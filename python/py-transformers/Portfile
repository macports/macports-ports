# -*- coding: utf-8; mode: tcl; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -*- vim:fenc=utf-8:ft=tcl:et:sw=4:ts=4:sts=4

PortSystem          1.0
PortGroup           github 1.0
PortGroup           python 1.0

github.setup        huggingface transformers 2.2.1 v
revision            0
name                py-${github.project}
categories-append   textproc

license             Apache-2
maintainers         nomaintainer
platforms           darwin
supported_archs     noarch

description         State-of-the-art Natural Language Processing for\
                    TensorFlow 2.0 and PyTorch
long_description \
    ðŸ¤— Transformers (formerly known as pytorch-transformers and\
    pytorch-pretrained-bert) provides state-of-the-art general-purpose\
    architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet,\
    CTRL...) for Natural Language Understanding (NLU) and Natural\
    Language Generation (NLG) with over 32+ pretrained models in 100+\
    languages and deep interoperability between TensorFlow 2.0 and\
    PyTorch.

homepage            https://huggingface.co/transformers/

python.versions     37 38

checksums           rmd160  6ce2698caee7f059fda0e474c0a81e2eb806075c \
                    sha256  fcdaa2109e03eb5768041511321338729a25fb657f833e68d3c6e552936c7590 \
                    size    2546910

if {${name} ne ${subport}} {
    # see https://github.com/huggingface/transformers/blob/master/setup.py
    depends_lib-append \
                    port:py${python.version}-setuptools
    depends_run-append \
                    port:py${python.version}-boto3 \
                    port:py${python.version}-numpy \
                    port:py${python.version}-protobuf3 \
                    port:py${python.version}-regex \
                    port:py${python.version}-requests \
                    port:py${python.version}-sacremoses \
                    port:py${python.version}-sentencepiece \
                    port:py${python.version}-tqdm

    depends_test-append \
                    port:py${python.version}-pytest

    test.run        yes
    test.cmd        py.test-${python.branch}
    test.pre_args   -sv
    test.target     ./transformers/tests/
}
