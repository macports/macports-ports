# -*- coding: utf-8; mode: tcl; tab-width: 4; indent-tabs-mode: nil; c-basic-offset: 4 -*- vim:fenc=utf-8:ft=tcl:et:sw=4:ts=4:sts=4

PortSystem          1.0
PortGroup           github 1.0
PortGroup           mpi 1.0
PortGroup           python 1.0

name                py-pytorch
version             2.0.0
revision            0
github.setup        pytorch pytorch ${version} v
fetch.type          git

supported_archs     arm64 x86_64
# third_party/pthreadpool needs DISPATCH_APPLY_AUTO (as of torch 2.0.0)
platforms           {darwin >= 16}

license             BSD

maintainers         nomaintainer

description         Tensors and dynamic neural networks in Python \
                    with strong GPU acceleration

long_description    PyTorch is a Python package that provides two \
                    high-level features: Tensor computation (like \
                    NumPy) with strong GPU acceleration\; Deep neural \
                    networks built on a tape-based autograd \
                    system. You can reuse your favorite Python \
                    packages such as NumPy, SciPy and Cython to extend \
                    PyTorch when needed.

homepage            https://pytorch.org/

python.versions     38 39 310

mpi.setup

# Compiler selection
compiler.cxx_standard 2017

compiler.blacklist-append *gcc*

variant mkl description {Enable Intel Math Kernel Library support} { }

# py-mkl supports x86_64 and 10.12 and later only
if {${configure.build_arch} eq "x86_64" && !($universal_possible && [variant_isset universal])
        && !(${os.platform} eq "darwin" && ${os.major} <= 15)} {
    default_variants-append +mkl
}

platform darwin {
    # MPS support added in 10.13
    if {${os.major} >= 17} {
        variant mps description {Enable Apple Metal Performance Shaders (MPS) support} {
            use_xcode       yes

            build.env-append \
                APPLE=ON \
                USE_MPS=ON \
                USE_PYTORCH_METAL=ON \
                USE_PYTORCH_METAL_EXPORT=ON

            notes-append \
"
The port ${subport} is built with Apple Metal Performance Shaders (MPS)\
support for GPU hardware acceleration. To enable Apple GPU devices,\
use device \"mps\". Matrix multiplication example:

    import torch

    mpsDevice = torch.device(\"mps\" if\
        torch.backends.mps.is_available() else \"cpu\")
    x = torch.randn((10_000, 1_000), device=mpsDevice)
    cov = (x.T @ x)/x.shape\[0]
"
        }

        default_variants-append +mps
    }
}

if {${name} ne ${subport}} {

    depends_build-append \
        port:git \
        path:bin/doxygen:doxygen \
        port:cctools \
        path:bin/cmake:cmake \
        port:py${python.version}-setuptools

    depends_lib-append \
        port:eigen3 \
        port:gmp \
        port:mpfr \
        port:OpenBLAS \
        path:lib/opencv4/libopencv_core.dylib:opencv4 \
        port:zmq \
        port:zstd \
        port:tbb \
        port:google-glog \
        port:gflags \
        port:leveldb \
        port:lmdb \
        port:libomp \
        port:py${python.version}-click \
        port:py${python.version}-cffi \
        port:py${python.version}-future \
        port:py${python.version}-numpy \
        port:py${python.version}-pybind11 \
        port:py${python.version}-typing_extensions \
        port:py${python.version}-yaml

    depends_run-append \
        port:py${python.version}-onnx

    post-fetch {
        system -W ${worksrcpath} "git submodule update --init --recursive"
    }

    # Patch to fix init issue with google-glog 0.5.0, caused by breaking API change.
    # Refer to patch header for detailed background.
    # Upstream PyTorch issue: https://github.com/pytorch/pytorch/issues/58054
    # diff -NaurdwB ./py-pytorch-orig/c10/util/Logging.cpp ./py-pytorch-new/c10/util/Logging.cpp | sed -E -e 's/\.\/py-pytorch-(orig|new)/\.\//' | sed -E -e 's|/opt/local|@@PREFIX@@|g' > ~/Downloads/patch-glog-init-check.diff
    patchfiles-append        patch-glog-init-check.diff

    # Disable -Werror in third_party/fbgemm
    patchfiles-append       Werror.patch

    # Use Intel Math kernel Library
    if {[variant_isset mkl]} {
        patchfiles-append FindMKL-OMP.patch
        pre-build {
            # Hacks to get search paths into builds
            reinplace "s|/opt/intel/mkl|${python.prefix}|g" \
                cmake/Modules/FindMKL.cmake
            reinplace "s|mklvers \"intel64\"|mklvers \"\"|g" \
                cmake/Modules/FindMKL.cmake
            reinplace "s|MACPORTS_PREFIX|${prefix}|g" \
                cmake/Modules/FindMKL.cmake
        }
        depends_lib-append   port:py${python.version}-mkl
        depends_build-append port:py${python.version}-mkl-include
    }

    configure.ccache    yes

    # ZSTD support broke with 1.2.0-1.12.0. Check with future releases.
    build.env-append \
                    CMAKE_LIBRARY_PATH=${prefix}/lib:${prefix}/lib/libomp \
                    LIBRARY_PATH=${prefix}/lib:${prefix}/lib/libomp \
                    OpenCV_DIR=${prefix}/libexec/opencv4/cmake \
                    USE_CCACHE=OFF \
                    USE_CUDA=OFF \
                    USE_GFLAGS=ON \
                    USE_GLOG=ON \
                    USE_LEVELDB=ON \
                    USE_LITE_PROTO=ON \
                    USE_LMDB=ON \
                    USE_METAL=ON \
                    USE_NCCL=ON \
                    USE_OPENCV=ON \
                    USE_OPENMP=ON \
                    USE_ROCM=OFF \
                    USE_TBB=ON \
                    USE_ZMQ=ON \
                    USE_ZSTD=OFF

    build.dir       ${worksrcpath}
    build.post_args

    destroot.dir    ${worksrcpath}
    destroot.target install

    post-destroot {
        set py_torch_root ${python.pkgd}/torch
        foreach slib [glob -directory ${destroot}${py_torch_root} *.so] {
            system "install_name_tool -add_rpath ${py_torch_root}/lib ${slib}"
        }

        set docdir ${prefix}/share/doc/${subport}
        xinstall -d ${destroot}${docdir}
        xinstall -m 0644 -W ${worksrcpath} LICENSE README.md \
            ${destroot}${docdir}
    }

    # pytorch's tests all use GPU compilation
    if { [lsearch ${build.env} {USE_CUDA=OFF}] != -1 } {
        test.run    yes
    }
    
    livecheck.type  none

} else {

    # overload the github livecheck regex to look for versions that
    # are just numbers and '.', no letters (e.g., "3.7.3_rc2").
    github.livecheck.regex  {([0-9.]+)}

}
