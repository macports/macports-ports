--- ./deps/v8/src/base/platform/platform-posix.cc	2025-07-17 15:43:43.000000000 -0600
+++ ./deps/v8/src/base/platform/platform-posix.cc	2023-08-08 16:32:50.000000000 -0600
@@ -23,12 +23,12 @@
 #include <sys/types.h>
 #if defined(__APPLE__) || defined(__DragonFly__) || defined(__FreeBSD__) || \
     defined(__NetBSD__) || defined(__OpenBSD__)
-#include <sys/sysctl.h>  // for sysctl
+#include <sys/sysctl.h>  // NOLINT, for sysctl
 #endif
 
 #if defined(ANDROID) && !defined(V8_ANDROID_LOG_STDOUT)
 #define LOG_TAG "v8"
-#include <android/log.h>
+#include <android/log.h>  // NOLINT
 #endif
 
 #include <cmath>
@@ -52,7 +52,7 @@
 #endif
 
 #if V8_OS_LINUX
-#include <sys/prctl.h>  // for prctl
+#include <sys/prctl.h>  // NOLINT, for prctl
 #endif
 
 #if defined(V8_OS_FUCHSIA)
@@ -82,7 +82,7 @@
 #endif
 
 #if defined(V8_LIBC_GLIBC)
-extern "C" void* __libc_stack_end;
+extern "C" void* __libc_stack_end;  // NOLINT
 #endif
 
 namespace v8 {
@@ -111,13 +111,6 @@
 const int kMmapFd = -1;
 #endif  // !V8_OS_MACOSX
 
-#if defined(V8_TARGET_OS_MACOSX) && V8_HOST_ARCH_ARM64
-// During snapshot generation in cross builds, sysconf() runs on the Intel
-// host and returns host page size, while the snapshot needs to use the
-// target page size.
-constexpr int kAppleArmPageSize = 1 << 14;
-#endif
-
 const int kMmapFdOffset = 0;
 
 // TODO(v8:10026): Add the right permission flag to make executable pages
@@ -139,12 +132,8 @@
   UNREACHABLE();
 }
 
-enum class PageType { kShared, kPrivate };
-
-int GetFlagsForMemoryPermission(OS::MemoryPermission access,
-                                PageType page_type) {
-  int flags = MAP_ANONYMOUS;
-  flags |= (page_type == PageType::kShared) ? MAP_SHARED : MAP_PRIVATE;
+int GetFlagsForMemoryPermission(OS::MemoryPermission access) {
+  int flags = MAP_PRIVATE | MAP_ANONYMOUS;
   if (access == OS::MemoryPermission::kNoAccess) {
 #if !V8_OS_AIX && !V8_OS_FREEBSD && !V8_OS_QNX
     flags |= MAP_NORESERVE;
@@ -153,7 +142,7 @@
     flags |= MAP_LAZY;
 #endif  // V8_OS_QNX
   }
-#if V8_HAS_PTHREAD_JIT_WRITE_PROTECT
+#if V8_OS_MACOSX && V8_HOST_ARCH_ARM64 && defined(MAP_JIT)
   if (access == OS::MemoryPermission::kNoAccessWillJitLater) {
     flags |= MAP_JIT;
   }
@@ -161,27 +150,11 @@
   return flags;
 }
 
-void* Allocate(void* hint, size_t size, OS::MemoryPermission access,
-               PageType page_type) {
+void* Allocate(void* hint, size_t size, OS::MemoryPermission access) {
   int prot = GetProtectionFromMemoryPermission(access);
-  int flags = GetFlagsForMemoryPermission(access, page_type);
+  int flags = GetFlagsForMemoryPermission(access);
   void* result = mmap(hint, size, prot, flags, kMmapFd, kMmapFdOffset);
   if (result == MAP_FAILED) return nullptr;
-#if ENABLE_HUGEPAGE
-  if (result != nullptr && size >= kHugePageSize) {
-    const uintptr_t huge_start =
-        RoundUp(reinterpret_cast<uintptr_t>(result), kHugePageSize);
-    const uintptr_t huge_end =
-        RoundDown(reinterpret_cast<uintptr_t>(result) + size, kHugePageSize);
-    if (huge_end > huge_start) {
-      // Bail out in case the aligned addresses do not provide a block of at
-      // least kHugePageSize size.
-      madvise(reinterpret_cast<void*>(huge_start), huge_end - huge_start,
-              MADV_HUGEPAGE);
-    }
-  }
-#endif
-
   return result;
 }
 
@@ -259,18 +232,13 @@
 
 // static
 size_t OS::AllocatePageSize() {
-#if defined(V8_TARGET_OS_MACOSX) && V8_HOST_ARCH_ARM64
-  return kAppleArmPageSize;
-#else
-  static size_t page_size = static_cast<size_t>(sysconf(_SC_PAGESIZE));
-  return page_size;
-#endif
+  return static_cast<size_t>(sysconf(_SC_PAGESIZE));
 }
 
 // static
 size_t OS::CommitPageSize() {
-  // Commit and allocate page size are the same on posix.
-  return OS::AllocatePageSize();
+  static size_t page_size = getpagesize();
+  return page_size;
 }
 
 // static
@@ -288,13 +256,11 @@
     MutexGuard guard(rng_mutex.Pointer());
     GetPlatformRandomNumberGenerator()->NextBytes(&raw_addr, sizeof(raw_addr));
   }
-#if V8_HOST_ARCH_ARM64
-#if defined(V8_TARGET_OS_MACOSX)
+#if defined(__APPLE__)
+#if V8_TARGET_ARCH_ARM64
   DCHECK_EQ(1 << 14, AllocatePageSize());
+  raw_addr = RoundDown(raw_addr, 1 << 14);
 #endif
-  // Keep the address page-aligned, AArch64 supports 4K, 16K and 64K
-  // configurations.
-  raw_addr = RoundDown(raw_addr, AllocatePageSize());
 #endif
 #if defined(V8_USE_ADDRESS_SANITIZER) || defined(MEMORY_SANITIZER) || \
     defined(THREAD_SANITIZER) || defined(LEAK_SANITIZER)
@@ -305,7 +271,7 @@
   raw_addr &= 0x007fffff0000ULL;
   raw_addr += 0x7e8000000000ULL;
 #else
-#if V8_TARGET_ARCH_X64 || V8_TARGET_ARCH_ARM64
+#if V8_TARGET_ARCH_X64
   // Currently available CPUs have 48 bits of virtual addressing.  Truncate
   // the hint address to 46 bits to give the kernel a fighting chance of
   // fulfilling our placement request.
@@ -337,10 +303,6 @@
   // 42 bits of virtual addressing. Truncate to 40 bits to allow kernel chance
   // to fulfill request.
   raw_addr &= uint64_t{0xFFFFFF0000};
-#elif V8_TARGET_ARCH_RISCV64
-  // TODO(RISCV): We need more information from the kernel to correctly mask
-  // this address for RISC-V. https://github.com/v8-riscv/v8/issues/375
-  raw_addr &= uint64_t{0xFFFFFF0000};
 #else
   raw_addr &= 0x3FFFF000;
 
@@ -382,7 +344,7 @@
   // Add the maximum misalignment so we are guaranteed an aligned base address.
   size_t request_size = size + (alignment - page_size);
   request_size = RoundUp(request_size, OS::AllocatePageSize());
-  void* result = base::Allocate(hint, request_size, access, PageType::kPrivate);
+  void* result = base::Allocate(hint, request_size, access);
   if (result == nullptr) return nullptr;
 
   // Unmap memory allocated before the aligned base address.
@@ -408,12 +370,6 @@
 }
 
 // static
-void* OS::AllocateShared(size_t size, MemoryPermission access) {
-  DCHECK_EQ(0, size % AllocatePageSize());
-  return base::Allocate(nullptr, size, access, PageType::kShared);
-}
-
-// static
 bool OS::Free(void* address, const size_t size) {
   DCHECK_EQ(0, reinterpret_cast<uintptr_t>(address) % AllocatePageSize());
   DCHECK_EQ(0, size % AllocatePageSize());
@@ -455,7 +411,7 @@
 // The cost is a syscall that effectively no-ops.
 // TODO(erikchen): Fix this to only call MADV_FREE_REUSE when necessary.
 // https://crbug.com/823915
-#if defined(V8_OS_MACOSX)
+#if defined(OS_MACOSX)
   if (access != OS::MemoryPermission::kNoAccess)
     madvise(address, size, MADV_FREE_REUSE);
 #endif
@@ -466,7 +422,7 @@
 bool OS::DiscardSystemPages(void* address, size_t size) {
   DCHECK_EQ(0, reinterpret_cast<uintptr_t>(address) % CommitPageSize());
   DCHECK_EQ(0, size % CommitPageSize());
-#if defined(V8_OS_MACOSX)
+#if defined(OS_MACOSX)
   // On OSX, MADV_FREE_REUSABLE has comparable behavior to MADV_FREE, but also
   // marks the pages with the reusable bit, which allows both Activity Monitor
   // and memory-infra to correctly track the pages.
@@ -539,8 +495,6 @@
 #elif V8_HOST_ARCH_S390
   // Software breakpoint instruction is 0x0001
   asm volatile(".word 0x0001");
-#elif V8_HOST_ARCH_RISCV64
-  asm("ebreak");
 #else
 #error Unsupported host architecture.
 #endif
@@ -593,7 +547,7 @@
 OS::MemoryMappedFile* OS::MemoryMappedFile::create(const char* name,
                                                    size_t size, void* initial) {
   if (FILE* file = fopen(name, "w+")) {
-    if (size == 0) return new PosixMemoryMappedFile(file, nullptr, 0);
+    if (size == 0) return new PosixMemoryMappedFile(file, 0, 0);
     size_t result = fwrite(initial, 1, size, file);
     if (result == size && !ferror(file)) {
       void* memory = mmap(OS::GetRandomMmapAddr(), result,
@@ -713,7 +667,9 @@
   return tmpfile();
 }
 
-const char* const OS::LogFileOpenMode = "w+";
+
+const char* const OS::LogFileOpenMode = "w";
+
 
 void OS::Print(const char* format, ...) {
   va_list args;
@@ -951,7 +907,8 @@
   buffer[kBufferSize - 1] = '\0';
   char* period_pos = strchr(buffer, '.');
   *period_pos = '\0';
-  int kernel_version_major = static_cast<int>(strtol(buffer, nullptr, 10));
+  int kernel_version_major =
+      static_cast<int>(strtol(buffer, nullptr, 10));  // NOLINT
   // The constants below are taken from pthreads.s from the XNU kernel
   // sources archive at www.opensource.apple.com.
   if (kernel_version_major < 11) {
@@ -1033,7 +990,7 @@
     !defined(V8_OS_SOLARIS)
 
 // static
-Stack::StackSlot Stack::GetStackStart() {
+void* Stack::GetStackStart() {
   pthread_attr_t attr;
   int error = pthread_getattr_np(pthread_self(), &attr);
   if (!error) {
@@ -1044,6 +1001,7 @@
     pthread_attr_destroy(&attr);
     return reinterpret_cast<uint8_t*>(base) + size;
   }
+  pthread_attr_destroy(&attr);
 
 #if defined(V8_LIBC_GLIBC)
   // pthread_getattr_np can fail for the main thread. In this case
@@ -1051,18 +1009,15 @@
   // the start of the stack.
   // See https://code.google.com/p/nativeclient/issues/detail?id=3431.
   return __libc_stack_end;
-#else
-  return nullptr;
 #endif  // !defined(V8_LIBC_GLIBC)
+  return nullptr;
 }
 
 #endif  // !defined(V8_OS_FREEBSD) && !defined(V8_OS_MACOSX) &&
         // !defined(_AIX) && !defined(V8_OS_SOLARIS)
 
 // static
-Stack::StackSlot Stack::GetCurrentStackPosition() {
-  return __builtin_frame_address(0);
-}
+Stack::StackSlot Stack::GetCurrentStackPosition() { return __builtin_frame_address(0); }
 
 #undef LOG_TAG
 #undef MAP_ANONYMOUS
